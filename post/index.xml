<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Tuna&#39;s Site</title>
    <link>https://tunahsu.github.io/post/</link>
    <description>Recent content in Posts on Tuna&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 08 Dec 2023 02:07:50 +0800</lastBuildDate>
    <atom:link href="https://tunahsu.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2024 預聘/研替心得</title>
      <link>https://tunahsu.github.io/post/2024-rdss/</link>
      <pubDate>Fri, 08 Dec 2023 02:07:50 +0800</pubDate>
      <guid>https://tunahsu.github.io/post/2024-rdss/</guid>
      <description>&lt;p&gt;其實本來應該要是2023年的心得，本來想說等今年6月確定可以口試之後再來找今年度的研替，沒想到上研替官網才知道今年第四次徵選取消QQ，所以我面臨的是直接畢業收海陸的兵單，或是延畢一學期等明年的梯次，後來我選擇後者所以才有這篇文😹&lt;/p&gt;</description>
    </item>
    <item>
      <title>RepLKNet</title>
      <link>https://tunahsu.github.io/post/replknet/</link>
      <pubDate>Wed, 07 Sep 2022 16:05:31 +0800</pubDate>
      <guid>https://tunahsu.github.io/post/replknet/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.06717&#34;&gt;Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs&lt;/a&gt; 近年來 Transformer 的崛起，普遍認為 self-attention 在影像領域可以表現得比 CNN 更好，這篇發表在 CVPR 2022 上的研究表示認為這不是因為 Self-attention 的設計形式(query-key-value)，而是因為其有效感受野特別大，因此作者提出了提出了超大 kernel 的模型，在一系列的實驗下證明較大的卷積核在現代模型優化的設計下，計算量並不會提升多少且在一些 downstream tasks 的效能更甚於較深但 kernel 較小的網路架構。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GaborNet 在卷積神經網路中可學習的 Gabor 濾波器參數</title>
      <link>https://tunahsu.github.io/post/gabornet/</link>
      <pubDate>Mon, 02 May 2022 22:56:56 +0800</pubDate>
      <guid>https://tunahsu.github.io/post/gabornet/</guid>
      <description>&lt;p&gt;以 Dennis Gabor 命名的 Gabor 濾波器，是一種用於紋理分析的線性濾波器，主要分析的是影像在特定區域的特定方向上是否有特定頻率的內容，許多視覺科學家認為 Gabor 的頻率和方向的表達與人類的視覺系統很類似。研究發現，Gabor 濾波器特別適合用於紋理表示和辨識。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DynCNN 用於監控影像的動態卷積神經網路</title>
      <link>https://tunahsu.github.io/post/dyncnn/</link>
      <pubDate>Wed, 13 Apr 2022 15:16:10 +0800</pubDate>
      <guid>https://tunahsu.github.io/post/dyncnn/</guid>
      <description>&lt;p&gt;智慧監控所使用的CNN的架構大部分是來自 ImageNet Challenge 比賽中獲勝的網路架構，這些較著名的CNN 架構具有更深層且更複雜的神經網路從而達到更高的精度，但在現今的硬體技術發展下，高端硬體設備已經可以讓這些複雜的神經網路達成 real-time 的效果。但在智慧監控領域中多通道的影像，需要同時進行處理並實現及時運算，考量這些大量監視器影像所需的計算成本，以現今的硬體設備還是難以達成&lt;/p&gt;</description>
    </item>
    <item>
      <title>Winograd algorithm 卷積神經網路中的加速卷積算法</title>
      <link>https://tunahsu.github.io/post/winograd-algorithm/</link>
      <pubDate>Tue, 12 Apr 2022 16:53:08 +0800</pubDate>
      <guid>https://tunahsu.github.io/post/winograd-algorithm/</guid>
      <description>&lt;p&gt;作為首篇學習筆記，來記錄一下最近閱讀學長論文時文中的 Winograd 演算法，該方法可以減少矩陣乘法中的乘法運算，近年來有許多相關研究將其應用於加速 convolutional operation&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
